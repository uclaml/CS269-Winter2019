

Testing

## Overview

Deep learning has achieved great success in many applications such as image processing, speech recognition and Go games. However, the reason why deep learning is so powerful remains elusive. The goal of this course is to understand the successes of deep learning by studying and building the theoretical foundations of deep learning. Topics covered by this course include but are not limited to: expressive power of deep learning, optimization for deep learning, generalization performance of deep learning and robustness of deep learning. Instructor will give lectures on advanced topics of statistical learning theory. Students will present and discuss papers on the selected topics, and do a course project.

## Logistics

<!--University of California, Los Angeles  -->

- Time: **Monday and Wednesday 4:00PM - 5:50PM**
- Location: **WGYOUNG 4216**  
- Instructor: [Quanquan Gu](http://web.cs.ucla.edu/~qgu/) (Email: qgu@cs.ucla.edu)   
- Teaching Assistant: Xinzhu Bei (Email: xzbei@cs.ucla.edu)
- Office hours: TBD 

## Textbook

There is no required textbook. The following are recommended textbooks:

1. Shai Shalev-Shwartz, and Shai Ben-David. Understanding machine learning: From theory to algorithms. Cambridge University Press, 2014. 
2. 

## Grading Policy
 
 

## Schedule


| # | Date  | Topic  | pdf | ipynb  |
|----|----|----|----|----|
| | | **Part I: Statistical Learning Theory** | | |
| 1 | 1/7 |  Concentration Inequalities |  |  |
| 2 | 1/9 | Uniform Convergence |   | ---  |
| 3 | 1/14 | Rademacher Complexity |   | ---  |
| | | **Part II: Deep Learning Theory** | | |
| 10 | 2/6 | Generalization Error of DNN I | | |
